    def parse(self, response):
        page = 1
        varies = [
            "/div/div/div/div[2]/div[2]/div[1]/a",
            "/div/div[2]/div/div[2]/div[1]/div[1]/a",
            "/div/div/div/div[2]/div[1]/div[1]/a"
        ]
        for i in range(0, 22):
            amz = Amazon()
            amz['PageIndex'] = 1
            for r in varies:
                regex = '//*[@id="result_' + str(i) + '"]'
                regex += r
                attr = response.xpath(regex).attrib
                if attr.__len__() != 0:
                    break
            if attr.__len__() == 0:
                continue
            if 'title' in attr:
                amz["Title"] = attr["title"]
            if 'href' in attr:
                amz["Href"] = attr["href"]

            if amz["Href"] != "":
                amz['KeyWords'] = "a"
                amz["Href"].split('/dp/')
                amz['TargetKey'] = ""
                amz['MatchWords'] = ""
                amz['CurrentPageRank'] = i
                amz['TotalPageRank'] = i * page
                self.items.append(amz)
        le = LinkExtractor(restrict_css="#pagnNextLink")
        links=le.extract_links(response)
        if links:
            next_url = links[0].url
            #todo delay a period of time.
            time.sleep(1)
            return scrapy.Request(next_url, callback=self.parse)
        return self.items